{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Loading and exploring the dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"creditcard.csv\")\n",
        "\n",
        "# Check for missing values\n",
        "print(\"Missing Values:\\n\", df.isnull().sum())\n",
        "\n",
        "# Drop rows with missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Check class distribution\n",
        "print(\"Class Distribution:\\n\", df['Class'].value_counts())"
      ],
      "metadata": {
        "id": "QRCwl7Nqo-aS",
        "outputId": "78279965-9d3a-4b5f-e61a-b73b06bda92b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Values:\n",
            " Time      0\n",
            "V1        0\n",
            "V2        0\n",
            "V3        0\n",
            "V4        0\n",
            "V5        0\n",
            "V6        0\n",
            "V7        0\n",
            "V8        0\n",
            "V9        1\n",
            "V10       1\n",
            "V11       1\n",
            "V12       1\n",
            "V13       1\n",
            "V14       1\n",
            "V15       1\n",
            "V16       1\n",
            "V17       1\n",
            "V18       1\n",
            "V19       1\n",
            "V20       1\n",
            "V21       1\n",
            "V22       1\n",
            "V23       1\n",
            "V24       1\n",
            "V25       1\n",
            "V26       1\n",
            "V27       1\n",
            "V28       1\n",
            "Amount    1\n",
            "Class     1\n",
            "dtype: int64\n",
            "Class Distribution:\n",
            " Class\n",
            "0.0    89008\n",
            "1.0      211\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df['Amount'] = scaler.fit_transform(df[['Amount']])"
      ],
      "metadata": {
        "id": "ClhItW18pD95"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature Engineering\n",
        "# Extract Hour from Time feature\n",
        "df['Hour'] = (df['Time'] // 3600) % 24\n",
        "\n",
        "# Create Transaction Frequency feature\n",
        "df['Transaction_Frequency'] = df.groupby('Amount')['Amount'].transform('count')"
      ],
      "metadata": {
        "id": "OFYkr_M4pJKs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling Class Imbalance\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "X = df.drop(columns=['Class'])\n",
        "y = df['Class']\n",
        "\n",
        "# Apply SMOTE if enough fraud samples exist, else use undersampling\n",
        "if y.value_counts()[1] > 5:\n",
        "    smote = SMOTE(sampling_strategy='auto', k_neighbors=2, random_state=42)\n",
        "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "else:\n",
        "    undersampler = RandomUnderSampler(sampling_strategy=0.5, random_state=42)\n",
        "    X_resampled, y_resampled = undersampler.fit_resample(X, y)"
      ],
      "metadata": {
        "id": "RxP-ycDwpQNB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split data into train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "xWGZJy6qpWMj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train multiple models\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"Training {name}...\")\n",
        "    model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "__XHfu2KpeFZ",
        "outputId": "3be2f8b0-3dbd-4518-d47a-142ccec07836",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Logistic Regression...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Random Forest...\n",
            "Training XGBoost...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [16:20:17] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluate the models\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "best_model = None\n",
        "best_score = 0\n",
        "\n",
        "for name, model in models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    auc_score = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
        "\n",
        "    print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"{name} ROC-AUC Score: {auc_score:.4f}\")\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "    print(\"\\n\")\n",
        "\n",
        "    if auc_score > best_score:\n",
        "        best_score = auc_score\n",
        "        best_model = model"
      ],
      "metadata": {
        "id": "hgD15n-Ypqqd",
        "outputId": "e311bfc1-772b-475b-da7c-be9a349215ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.9755\n",
            "Logistic Regression ROC-AUC Score: 0.9955\n",
            "Confusion Matrix:\n",
            " [[17389   337]\n",
            " [  536 17342]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.97      0.98      0.98     17726\n",
            "         1.0       0.98      0.97      0.98     17878\n",
            "\n",
            "    accuracy                           0.98     35604\n",
            "   macro avg       0.98      0.98      0.98     35604\n",
            "weighted avg       0.98      0.98      0.98     35604\n",
            "\n",
            "\n",
            "\n",
            "Random Forest Accuracy: 0.9998\n",
            "Random Forest ROC-AUC Score: 1.0000\n",
            "Confusion Matrix:\n",
            " [[17721     5]\n",
            " [    2 17876]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00     17726\n",
            "         1.0       1.00      1.00      1.00     17878\n",
            "\n",
            "    accuracy                           1.00     35604\n",
            "   macro avg       1.00      1.00      1.00     35604\n",
            "weighted avg       1.00      1.00      1.00     35604\n",
            "\n",
            "\n",
            "\n",
            "XGBoost Accuracy: 0.9999\n",
            "XGBoost ROC-AUC Score: 1.0000\n",
            "Confusion Matrix:\n",
            " [[17722     4]\n",
            " [    0 17878]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00     17726\n",
            "         1.0       1.00      1.00      1.00     17878\n",
            "\n",
            "    accuracy                           1.00     35604\n",
            "   macro avg       1.00      1.00      1.00     35604\n",
            "weighted avg       1.00      1.00      1.00     35604\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the best model\n",
        "import joblib\n",
        "\n",
        "joblib.dump(best_model, \"credit_fraud_model.pkl\")\n",
        "print(f\"Model training complete. The best model has been saved as credit_fraud_model.pkl with ROC-AUC Score: {best_score:.4f}\")"
      ],
      "metadata": {
        "id": "fJ7fwEOlptrp",
        "outputId": "296cf405-b530-4b55-ebe3-1df2a8591e57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training complete. The best model has been saved as credit_fraud_model.pkl with ROC-AUC Score: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Download the model\n",
        "from google.colab import files\n",
        "\n",
        "# Download the saved model\n",
        "files.download(\"credit_fraud_model.pkl\")"
      ],
      "metadata": {
        "id": "vzWtAZEaqodM",
        "outputId": "fe2c75a7-a72d-424d-f82a-e78bb78c2d52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3ee5dcc7-434b-43d2-83c1-3561dd7e6a61\", \"credit_fraud_model.pkl\", 187861)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}